{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('XWb:', array([[-0.35999998,  0.28      ]], dtype=float32))\n",
      "('y:', array([[ 0.  ,  0.28]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "W = tf.Variable([[-0.5,-0.2],\n",
    "                [-0.3,0.4],\n",
    "                [-0.5,0.2]])\n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "\n",
    "XWb = tf.matmul(X,W)+b\n",
    "y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:',sess.run(XWb))\n",
    "    print('y:', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('XWb:', array([[-0.35999998,  0.28      ]], dtype=float32))\n",
      "('y:', array([[ 0.41095957,  0.56954622]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#sigmoid激活函数\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable([[-0.5,-0.2],\n",
    "                [-0.3, 0.4],\n",
    "                [-0.5, 0.2]])\n",
    "b = tf.Variable([[0.1, 0.2]])\n",
    "\n",
    "XWb = tf.matmul(X,W)+b\n",
    "\n",
    "y = tf.nn.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:',sess.run(XWb))\n",
    "    print('y:', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('b:', array([[ 0.19723237, -0.57399565]], dtype=float32))\n",
      "('W:', array([[-0.49489957,  0.17356798],\n",
      "       [ 0.31766674,  1.12940657],\n",
      "       [ 0.32945701, -0.81234473]], dtype=float32))\n",
      "('y:', array([[ 0.19458871,  0.        ]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#以正态分布的随机数生成权重与偏差的初始值\n",
    "W = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('b:', sess.run(b))\n",
    "    print('W:', sess.run(W))\n",
    "    print('y:', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.9808203   1.64421785 -0.48781005  0.67302376 -0.52207488]\n"
     ]
    }
   ],
   "source": [
    "#正态分布随机数\n",
    "ts_norm = tf.random_normal([1000])\n",
    "\n",
    "with tf.Session() as session:\n",
    "    norm_data = ts_norm.eval()\n",
    "    \n",
    "print(norm_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b961df450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(norm_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以placeholder传入X值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[ 0.75621879 -0.17452425]]\n",
      "_W:\n",
      "[[ 0.11709695  1.3866986 ]\n",
      " [ 0.22174695  0.26039377]\n",
      " [ 0.68829119  0.92647582]]\n",
      "_X:\n",
      "[[ 0.40000001  0.2         0.40000001]]\n",
      "_y:\n",
      "[[ 1.12272346  0.80282432]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3,2]))\n",
    "h = tf.Variable(tf.random_normal([1,2]))\n",
    "X = tf.placeholder('float', [None,3])\n",
    "y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2,0.4]])\n",
    "    (_b, _W, _X, _y) = sess.run((b,W,X,y), feed_dict={X:X_array})\n",
    "    print('b:');print(_b)\n",
    "    print('_W:');print(_W)\n",
    "    print('_X:');print(_X)\n",
    "    print('_y:');print(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建Layer函数以矩阵运算仿真神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim,output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W)+b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.5       ]]\n",
      "hidden layer h:\n",
      "[[ 0.          0.          0.18070343]]\n",
      "output layer y:\n",
      "[[ 1.7026571   0.20206237]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 4])\n",
    "h = layer(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)\n",
    "y = layer(output_dim=2, input_dim=3, inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y) =  sess.run((X,h,y), feed_dict={X:X_array})\n",
    "    \n",
    "    print('input layer X:');print(layer_X)\n",
    "    print('hidden layer h:');print(layer_h)\n",
    "    print('output layer y:');print(layer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立layer_debug函数显示权重与偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_debug(output_dim, input_dim, inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W)+b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.5       ]]\n",
      "W1:\n",
      "[[-1.84562612 -0.39592779 -1.80490005]\n",
      " [-0.83943081 -1.34275281  0.04058271]\n",
      " [-0.61014766  0.38935891 -0.40449473]\n",
      " [ 0.42494005 -0.72122079 -0.58483118]]\n",
      "b1:\n",
      "[[ 2.89507127 -1.79414451  0.63702327]]\n",
      "hidden layer h:\n",
      "[[ 1.9573456  0.         0.       ]]\n",
      "W2:\n",
      "[[ 0.63538241  0.46541041]\n",
      " [-0.07047886 -1.10237646]\n",
      " [ 0.39096537 -0.66185409]]\n",
      "b2:\n",
      "[[ 0.3583056  -2.00548649]]\n",
      "output layer y:\n",
      "[[ 1.60196853 -1.09451747]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 4])\n",
    "h,W1,b1 = layer_debug(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)\n",
    "y,W2,b2 = layer_debug(output_dim=2, input_dim=3, inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y,W1,b1,W2,b2) =  sess.run((X,h,y,W1,b1,W2,b2), feed_dict={X:X_array})\n",
    "    \n",
    "    print('input layer X:');print(layer_X)\n",
    "    print('W1:');print(W1)\n",
    "    print('b1:');print(b1)\n",
    "    print('hidden layer h:');print(layer_h)\n",
    "    print('W2:');print(W2)\n",
    "    print('b2:');print(b2)\n",
    "    print('output layer y:');print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
